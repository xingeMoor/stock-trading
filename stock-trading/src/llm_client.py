"""
LLM å®¢æˆ·ç«¯
é›†æˆçœŸå®çš„ LLM API è°ƒç”¨ (OpenAI å…¼å®¹æ ¼å¼)
"""
import os
import json
import requests
from typing import Dict, Any, Optional, List
from datetime import datetime


class LLMClient:
    """
    LLM å®¢æˆ·ç«¯
    æ”¯æŒå¤šç§æ¨¡å‹ï¼šQwenã€OpenAI ç­‰
    """
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 base_url: Optional[str] = None,
                 model: str = "qwen3.5-plus-2026-02-15"):
        """
        åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        
        Args:
            api_key: API Key (é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–)
            base_url: API åŸºç¡€ URL (é»˜è®¤ä½¿ç”¨é˜¿é‡Œäº‘ dashscope)
            model: æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv('DASHSCOPE_API_KEY', 
                                           'sk-sp-a184e2d7f771427a9b0c3c869992ff5a')
        self.base_url = base_url or 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        self.model = model
        
        print(f"ğŸ¤– LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹ï¼š{model}")
        print(f"   API: {self.base_url}")
    
    def chat(self, messages: List[Dict[str, str]], 
             temperature: float = 0.7,
             max_tokens: int = 2000,
             **kwargs) -> Dict[str, Any]:
        """
        èŠå¤©è¡¥å…¨ API
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "..."}]
            temperature: æ¸©åº¦ (0-1)
            max_tokens: æœ€å¤§ token æ•°
        
        Returns:
            LLM å“åº”
        """
        url = f"{self.base_url}/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            **kwargs
        }
        
        try:
            print(f"   ğŸ“¡ è°ƒç”¨ LLM API...")
            print(f"      æ¶ˆæ¯æ•°ï¼š{len(messages)}")
            print(f"      è¾“å…¥é•¿åº¦ï¼š{sum(len(m.get('content', '')) for m in messages)} å­—ç¬¦")
            
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            
            print(f"   âœ… LLM å“åº”æˆåŠŸ")
            print(f"      è¾“å‡ºé•¿åº¦ï¼š{len(result.get('choices', [{}])[0].get('message', {}).get('content', ''))} å­—ç¬¦")
            print(f"      Token ä½¿ç”¨ï¼š{result.get('usage', {})}")
            
            return {
                'success': True,
                'content': result['choices'][0]['message']['content'],
                'usage': result.get('usage', {}),
                'raw': result
            }
            
        except requests.exceptions.RequestException as e:
            print(f"   âŒ LLM API è°ƒç”¨å¤±è´¥ï¼š{e}")
            return {
                'success': False,
                'error': str(e),
                'content': ''
            }
    
    def chat_with_json_output(self, system_prompt: str, 
                               user_prompt: str,
                               temperature: float = 0.3) -> Dict[str, Any]:
        """
        èŠå¤©å¹¶å¼ºåˆ¶ JSON è¾“å‡º
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            temperature: æ¸©åº¦ (å»ºè®® 0.3 ä»¥ä¸‹ä¿è¯ JSON æ ¼å¼)
        
        Returns:
            è§£æåçš„ JSON æ•°æ®
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        response = self.chat(messages, temperature=temperature)
        
        if not response['success']:
            return {
                'success': False,
                'error': response.get('error', 'Unknown error'),
                'data': {}
            }
        
        # è§£æ JSON
        content = response['content']
        parsed_data = self._parse_json_content(content)
        
        return {
            'success': True,
            'data': parsed_data,
            'raw_content': content,
            'usage': response.get('usage', {})
        }
    
    def _parse_json_content(self, content: str) -> Dict[str, Any]:
        """
        è§£æ JSON å†…å®¹
        """
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(content.strip())
        except json.JSONDecodeError:
            # å°è¯•æå– JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except:
                    pass
            
            # è§£æå¤±è´¥
            print(f"   âš ï¸ JSON è§£æå¤±è´¥ï¼Œè¿”å›ç©ºå­—å…¸")
            return {}
    
    def analyze_with_role(self, role: str, task: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨æŒ‡å®šè§’è‰²è¿›è¡Œåˆ†æ
        
        Args:
            role: è§’è‰²åç§° (å¦‚ "åŸºæœ¬é¢åˆ†æå¸ˆ", "æŠ€æœ¯åˆ†æå¸ˆ")
            task: ä»»åŠ¡æè¿°
            data: åˆ†ææ•°æ®
        
        Returns:
            åˆ†æç»“æœ
        """
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{role}ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼š{task}
è¯·è¾“å‡º JSON æ ¼å¼çš„åˆ†æç»“æœï¼Œä¸è¦åŒ…å« Markdown æ ¼å¼ã€‚"""
        
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹æ•°æ®ï¼š

{json.dumps(data, indent=2, ensure_ascii=False)}

è¯·è¾“å‡º JSON æ ¼å¼çš„åˆ†æç»“æœã€‚"""
        
        return self.chat_with_json_output(system_prompt, user_prompt)


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def get_llm_client(model: str = "qwen3.5-plus-2026-02-15") -> LLMClient:
    """è·å– LLM å®¢æˆ·ç«¯å®ä¾‹"""
    return LLMClient(model=model)


def llm_analyze(role: str, task: str, data: Dict[str, Any], 
                model: str = "qwen3.5-plus-2026-02-15") -> Dict[str, Any]:
    """
    å¿«é€Ÿè°ƒç”¨ LLM åˆ†æ
    
    Args:
        role: è§’è‰²åç§°
        task: ä»»åŠ¡æè¿°
        data: åˆ†ææ•°æ®
        model: æ¨¡å‹åç§°
    
    Returns:
        åˆ†æç»“æœ
    """
    client = get_llm_client(model)
    return client.analyze_with_role(role, task, data)


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    print("="*60)
    print("ğŸ¤– LLM å®¢æˆ·ç«¯ - æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = LLMClient()
    
    # æµ‹è¯• 1: ç®€å•å¯¹è¯
    print(f"\nã€æµ‹è¯• 1ã€‘ç®€å•å¯¹è¯")
    response = client.chat([
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
    ])
    
    if response['success']:
        print(f"âœ… å“åº”ï¼š{response['content'][:100]}...")
    
    # æµ‹è¯• 2: JSON è¾“å‡º
    print(f"\nã€æµ‹è¯• 2ã€‘JSON æ ¼å¼è¾“å‡º")
    response = client.chat_with_json_output(
        system_prompt="ä½ æ˜¯ä¸€ä½è‚¡ç¥¨åˆ†æå¸ˆã€‚è¯·è¾“å‡º JSON æ ¼å¼çš„åˆ†æç»“æœã€‚",
        user_prompt="""
è¯·åˆ†æä»¥ä¸‹è‚¡ç¥¨æ•°æ®ï¼š
- ä»£ç ï¼šGOOGL
- å½“å‰ä»·æ ¼ï¼š$175
- P/E: 25.5
- RSI: 45

è¯·ç»™å‡ºè¯„çº§ (BUY/HOLD/SELL) å’Œç†ç”±ã€‚
"""
    )
    
    if response['success']:
        print(f"âœ… åˆ†æç»“æœï¼š{json.dumps(response['data'], indent=2, ensure_ascii=False)}")
    else:
        print(f"âŒ å¤±è´¥ï¼š{response['error']}")
    
    # æµ‹è¯• 3: è§’è‰²æ‰®æ¼”åˆ†æ
    print(f"\nã€æµ‹è¯• 3ã€‘è§’è‰²æ‰®æ¼” - åŸºæœ¬é¢åˆ†æå¸ˆ")
    test_data = {
        'symbol': 'GOOGL',
        'pe_ratio': 25.5,
        'roe': 0.28,
        'revenue_growth': 0.12,
        'net_margin': 0.22
    }
    
    result = client.analyze_with_role(
        role="åŸºæœ¬é¢åˆ†æå¸ˆ",
        task="åˆ†æå…¬å¸è´¢åŠ¡çŠ¶å†µï¼Œç»™å‡ºè¯„çº§å’Œç›®æ ‡ä»·",
        data=test_data
    )
    
    if result['success']:
        print(f"âœ… åˆ†æå®Œæˆï¼š{json.dumps(result['data'], indent=2, ensure_ascii=False)[:500]}...")
    
    print(f"\n{'='*60}")
    print("âœ… LLM å®¢æˆ·ç«¯æµ‹è¯•å®Œæˆï¼")
