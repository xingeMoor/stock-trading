"""
æœ¬åœ°æ•°æ®æ¹– - Data Lake
æ ¸å¿ƒåŠŸèƒ½:
1. SQLiteå†å²æ•°æ®å­˜å‚¨ (3-5å¹´æ•°æ®)
2. æ•°æ®é¢„çƒ­æœºåˆ¶ (å¼€ç›˜å‰é¢„åŠ è½½)
3. å¢é‡æ›´æ–° (åªæ›´æ–°æœ€æ–°æ•°æ®)
4. å¤šæºæ•°æ®èåˆä¸æ ¡éªŒ
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import json
import hashlib

# æ•°æ®åº“è·¯å¾„
DB_DIR = os.path.join(os.path.dirname(__file__), '..', 'data', 'lake')
os.makedirs(DB_DIR, exist_ok=True)

class DataLake:
    """
    æœ¬åœ°æ•°æ®æ¹–
    
    è®¾è®¡åŸåˆ™:
    - æŒ‰å¸‚åœºåˆ†åº“ (a_share.db / us_stock.db)
    - æŒ‰è¡¨å­˜å‚¨ä¸åŒç²’åº¦æ•°æ® (daily / weekly / monthly)
    - å…ƒæ•°æ®è®°å½•æ›´æ–°æ—¶é—´å’Œæ¥æº
    """
    
    def __init__(self):
        self.connections = {}
        
    def _get_db_path(self, market: str) -> str:
        """è·å–æ•°æ®åº“è·¯å¾„"""
        db_name = f"{market.lower().replace(' ', '_')}.db"
        return os.path.join(DB_DIR, db_name)
    
    def _get_connection(self, market: str) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        if market not in self.connections:
            db_path = self._get_db_path(market)
            conn = sqlite3.connect(db_path, check_same_thread=False)
            conn.row_factory = sqlite3.Row
            self.connections[market] = conn
            self._init_tables(market)
        return self.connections[market]
    
    def _init_tables(self, market: str):
        """åˆå§‹åŒ–æ•°æ®è¡¨"""
        conn = self.connections[market]
        cursor = conn.cursor()
        
        # Kçº¿æ•°æ®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS kline_daily (
                symbol TEXT NOT NULL,
                date TEXT NOT NULL,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume INTEGER,
                amount REAL,
                change_pct REAL,
                turnover REAL,
                updated_at TEXT,
                source TEXT,
                PRIMARY KEY (symbol, date)
            )
        ''')
        
        # å®æ—¶è¡Œæƒ…å¿«ç…§è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS realtime_snapshots (
                symbol TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                price REAL,
                open REAL,
                high REAL,
                low REAL,
                volume INTEGER,
                bid REAL,
                ask REAL,
                PRIMARY KEY (symbol, timestamp)
            )
        ''')
        
        # å…ƒæ•°æ®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metadata (
                symbol TEXT PRIMARY KEY,
                name TEXT,
                sector TEXT,
                market_cap REAL,
                first_date TEXT,
                last_date TEXT,
                total_records INTEGER,
                last_updated TEXT,
                data_source TEXT
            )
        ''')
        
        # æ›´æ–°æ—¥å¿—è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS update_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT,
                update_type TEXT,
                start_date TEXT,
                end_date TEXT,
                records_count INTEGER,
                update_time TEXT,
                status TEXT,
                message TEXT
            )
        ''')
        
        conn.commit()
    
    def save_kline(self, market: str, symbol: str, df: pd.DataFrame, source: str = "api"):
        """
        ä¿å­˜Kçº¿æ•°æ®
        
        Args:
            market: å¸‚åœº (Aè‚¡/US)
            symbol: è‚¡ç¥¨ä»£ç 
            df: DataFrameåŒ…å«OHLCVæ•°æ®
            source: æ•°æ®æ¥æº
        """
        if df.empty:
            return
        
        conn = self._get_connection(market)
        
        # æ ‡å‡†åŒ–æ•°æ®
        df = df.copy()
        df['symbol'] = symbol
        df['updated_at'] = datetime.now().isoformat()
        df['source'] = source
        
        # ç¡®ä¿åˆ—åæ­£ç¡®
        column_mapping = {
            'æ—¥æœŸ': 'date',
            'date': 'date',
            'å¼€ç›˜': 'open',
            'open': 'open',
            'æ”¶ç›˜': 'close',
            'close': 'close',
            'æœ€é«˜': 'high',
            'high': 'high',
            'æœ€ä½': 'low',
            'low': 'low',
            'æˆäº¤é‡': 'volume',
            'volume': 'volume',
            'æˆäº¤é¢': 'amount',
            'amount': 'amount',
            'æ¶¨è·Œå¹…': 'change_pct',
            'change_pct': 'change_pct',
            'æ¢æ‰‹ç‡': 'turnover',
            'turnover': 'turnover'
        }
        
        df = df.rename(columns=column_mapping)
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = ['symbol', 'date', 'open', 'high', 'low', 'close', 
                        'volume', 'amount', 'change_pct', 'turnover', 'updated_at', 'source']
        
        for col in required_cols:
            if col not in df.columns:
                df[col] = None
        
        df = df[required_cols]
        
        # ä½¿ç”¨REPLACE INTOå®ç°upsert
        cursor = conn.cursor()
        for _, row in df.iterrows():
            cursor.execute('''
                REPLACE INTO kline_daily 
                (symbol, date, open, high, low, close, volume, amount, 
                 change_pct, turnover, updated_at, source)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', tuple(row))
        
        conn.commit()
        
        # æ›´æ–°å…ƒæ•°æ®
        self._update_metadata(market, symbol, df)
        
        print(f"   âœ… {symbol}: ä¿å­˜ {len(df)} æ¡è®°å½•")
    
    def _update_metadata(self, market: str, symbol: str, df: pd.DataFrame):
        """æ›´æ–°å…ƒæ•°æ®"""
        conn = self._get_connection(market)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO metadata
            (symbol, first_date, last_date, total_records, last_updated)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            symbol,
            df['date'].min() if not df.empty else None,
            df['date'].max() if not df.empty else None,
            len(df),
            datetime.now().isoformat()
        ))
        
        conn.commit()
    
    def get_kline(self, market: str, symbol: str, 
                  start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        æŸ¥è¯¢Kçº¿æ•°æ®
        
        Returns:
            DataFrame with OHLCV data
        """
        conn = self._get_connection(market)
        
        query = "SELECT * FROM kline_daily WHERE symbol = ?"
        params = [symbol]
        
        if start_date:
            query += " AND date >= ?"
            params.append(start_date)
        
        if end_date:
            query += " AND date <= ?"
            params.append(end_date)
        
        query += " ORDER BY date"
        
        df = pd.read_sql_query(query, conn, params=params)
        
        return df
    
    def get_data_range(self, market: str, symbol: str) -> Dict[str, Any]:
        """è·å–æ•°æ®æ—¶é—´èŒƒå›´"""
        conn = self._get_connection(market)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT MIN(date) as first_date, MAX(date) as last_date, COUNT(*) as count
            FROM kline_daily WHERE symbol = ?
        ''', (symbol,))
        
        row = cursor.fetchone()
        return {
            'first_date': row['first_date'],
            'last_date': row['last_date'],
            'count': row['count']
        }
    
    def incremental_update(self, market: str, symbol: str, 
                          fetch_func, **fetch_kwargs) -> int:
        """
        å¢é‡æ›´æ–°æ•°æ®
        
        Args:
            market: å¸‚åœº
            symbol: è‚¡ç¥¨ä»£ç 
            fetch_func: æ•°æ®è·å–å‡½æ•°
            fetch_kwargs: ä¼ é€’ç»™fetch_funcçš„å‚æ•°
        
        Returns:
            æ–°å¢è®°å½•æ•°
        """
        print(f"\nğŸ”„ å¢é‡æ›´æ–° {symbol}...")
        
        # æ£€æŸ¥ç°æœ‰æ•°æ®èŒƒå›´
        existing = self.get_data_range(market, symbol)
        
        if existing['last_date']:
            # ä»æœ€åä¸€å¤©çš„ä¸‹ä¸€å¤©å¼€å§‹æ›´æ–°
            last_date = datetime.strptime(existing['last_date'], '%Y-%m-%d')
            start_date = (last_date + timedelta(days=1)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            
            if start_date > end_date:
                print(f"   â­ï¸  æ•°æ®å·²æ˜¯æœ€æ–° ({existing['last_date']})")
                return 0
            
            print(f"   ğŸ“… æ›´æ–°èŒƒå›´: {start_date} ~ {end_date}")
        else:
            # å…¨æ–°ä¸‹è½½ï¼Œè·å–3å¹´å†å²
            start_date = (datetime.now() - timedelta(days=1095)).strftime('%Y%m%d')
            end_date = datetime.now().strftime('%Y%m%d')
            print(f"   ğŸ“… å…¨æ–°ä¸‹è½½: {start_date} ~ {end_date}")
        
        # è·å–æ–°æ•°æ®
        try:
            df = fetch_func(symbol, start_date, end_date, **fetch_kwargs)
            
            if df is not None and not df.empty:
                self.save_kline(market, symbol, df, source="incremental_update")
                
                # è®°å½•æ›´æ–°æ—¥å¿—
                self._log_update(market, symbol, start_date, end_date, len(df), "success")
                
                return len(df)
            else:
                print(f"   âš ï¸  æ— æ–°æ•°æ®")
                return 0
                
        except Exception as e:
            print(f"   âŒ æ›´æ–°å¤±è´¥: {e}")
            self._log_update(market, symbol, start_date, end_date, 0, "failed", str(e))
            return 0
    
    def _log_update(self, market: str, symbol: str, start: str, end: str, 
                   count: int, status: str, message: str = ""):
        """è®°å½•æ›´æ–°æ—¥å¿—"""
        conn = self._get_connection(market)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO update_log
            (symbol, update_type, start_date, end_date, records_count, update_time, status, message)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (symbol, 'incremental', start, end, count, 
              datetime.now().isoformat(), status, message))
        
        conn.commit()
    
    def warmup_cache(self, symbols: List[str], market: str = "Aè‚¡"):
        """
        æ•°æ®é¢„çƒ­ - å¼€ç›˜å‰åŠ è½½å¸¸ç”¨æ•°æ®åˆ°å†…å­˜
        
        Args:
            symbols: éœ€è¦é¢„çƒ­çš„è‚¡ç¥¨åˆ—è¡¨
            market: å¸‚åœº
        """
        print(f"\nğŸ”¥ æ•°æ®é¢„çƒ­ ({market})...")
        print(f"   é¢„çƒ­æ ‡çš„: {len(symbols)} åª")
        
        warmed_data = {}
        
        for symbol in symbols:
            # åŠ è½½æœ€è¿‘60å¤©æ•°æ®
            df = self.get_kline(market, symbol, 
                               start_date=(datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d'))
            
            if not df.empty:
                warmed_data[symbol] = df
                print(f"   âœ… {symbol}: {len(df)} å¤©æ•°æ®")
            else:
                print(f"   âš ï¸  {symbol}: æ— æ•°æ®")
        
        print(f"   ğŸ”¥ é¢„çƒ­å®Œæˆ: {len(warmed_data)} åª")
        
        return warmed_data
    
    def batch_download(self, symbols: List[str], market: str, 
                       fetch_func, max_workers: int = 5):
        """
        æ‰¹é‡ä¸‹è½½å†å²æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            market: å¸‚åœº
            fetch_func: æ•°æ®è·å–å‡½æ•°
            max_workers: å¹¶å‘æ•°
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        print(f"\nğŸ“¥ æ‰¹é‡ä¸‹è½½ {market} æ•°æ®...")
        print(f"   æ ‡çš„æ•°é‡: {len(symbols)}")
        
        def download_one(symbol):
            try:
                count = self.incremental_update(market, symbol, fetch_func)
                return symbol, count, "success"
            except Exception as e:
                return symbol, 0, f"error: {e}"
        
        results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(download_one, sym): sym for sym in symbols}
            
            for future in as_completed(futures):
                symbol = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    sym, count, status = result
                    if status == "success":
                        print(f"   âœ… {sym}: +{count} æ¡")
                    else:
                        print(f"   âŒ {sym}: {status}")
                except Exception as e:
                    print(f"   âŒ {symbol}: {e}")
        
        # ç»Ÿè®¡
        success_count = sum(1 for r in results if r[2] == "success")
        total_new = sum(r[1] for r in results)
        
        print(f"\nğŸ“Š ä¸‹è½½å®Œæˆ: {success_count}/{len(symbols)} æˆåŠŸ")
        print(f"   æ–°å¢æ•°æ®: {total_new} æ¡")
        
        return results
    
    def get_stats(self, market: str) -> Dict[str, Any]:
        """è·å–æ•°æ®æ¹–ç»Ÿè®¡ä¿¡æ¯"""
        conn = self._get_connection(market)
        cursor = conn.cursor()
        
        # æ€»è‚¡ç¥¨æ•°
        cursor.execute("SELECT COUNT(DISTINCT symbol) FROM kline_daily")
        total_symbols = cursor.fetchone()[0]
        
        # æ€»è®°å½•æ•°
        cursor.execute("SELECT COUNT(*) FROM kline_daily")
        total_records = cursor.fetchone()[0]
        
        # æ—¥æœŸèŒƒå›´
        cursor.execute("SELECT MIN(date), MAX(date) FROM kline_daily")
        row = cursor.fetchone()
        
        # æœ€è¿‘æ›´æ–°
        cursor.execute("SELECT MAX(update_time) FROM update_log WHERE status = 'success'")
        last_update = cursor.fetchone()[0]
        
        return {
            'market': market,
            'total_symbols': total_symbols,
            'total_records': total_records,
            'date_range': f"{row[0]} ~ {row[1]}" if row[0] else None,
            'last_update': last_update
        }


def test_data_lake():
    """æµ‹è¯•æ•°æ®æ¹–"""
    print("ğŸ§ª æµ‹è¯•æœ¬åœ°æ•°æ®æ¹–\n")
    
    lake = DataLake()
    
    # æµ‹è¯•1: ä¿å­˜æ¨¡æ‹Ÿæ•°æ®
    print("1ï¸âƒ£  æµ‹è¯•ä¿å­˜æ•°æ®...")
    mock_df = pd.DataFrame({
        'date': ['2026-02-26', '2026-02-27', '2026-02-28'],
        'open': [10.0, 10.5, 11.0],
        'high': [10.8, 11.2, 11.5],
        'low': [9.8, 10.3, 10.8],
        'close': [10.5, 11.0, 11.3],
        'volume': [10000, 15000, 12000],
        'amount': [105000, 165000, 135600],
        'change_pct': [2.5, 4.8, 2.7],
        'turnover': [5.2, 7.8, 6.2]
    })
    
    lake.save_kline("Aè‚¡", "000001", mock_df, source="test")
    print("   âœ… ä¿å­˜æˆåŠŸ")
    
    # æµ‹è¯•2: æŸ¥è¯¢æ•°æ®
    print("\n2ï¸âƒ£  æµ‹è¯•æŸ¥è¯¢æ•°æ®...")
    df = lake.get_kline("Aè‚¡", "000001")
    print(f"   âœ… æŸ¥è¯¢åˆ° {len(df)} æ¡è®°å½•")
    print(f"   ğŸ“Š æœ€æ–°æ”¶ç›˜ä»·: Â¥{df['close'].iloc[-1]:.2f}")
    
    # æµ‹è¯•3: æ•°æ®èŒƒå›´
    print("\n3ï¸âƒ£  æµ‹è¯•æ•°æ®èŒƒå›´...")
    range_info = lake.get_data_range("Aè‚¡", "000001")
    print(f"   ğŸ“… èŒƒå›´: {range_info['first_date']} ~ {range_info['last_date']}")
    print(f"   ğŸ“ˆ æ€»æ•°: {range_info['count']} æ¡")
    
    # æµ‹è¯•4: ç»Ÿè®¡ä¿¡æ¯
    print("\n4ï¸âƒ£  æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
    stats = lake.get_stats("Aè‚¡")
    print(f"   ğŸ“Š {stats}")
    
    print("\nâœ… æ•°æ®æ¹–æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    test_data_lake()
