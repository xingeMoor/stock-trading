"""
çœŸå® LLM åˆ†æå¸ˆ - é€šè¿‡ sessions_spawn å®ç°
ä¸ä½¿ç”¨ä»»ä½• mock æˆ–è§„åˆ™åŒ–å›é€€
"""
import json
import os
import sys
from typing import Dict, Any
from datetime import datetime

# å¯¼å…¥ sessions_spawn ç”¨äºçœŸå® LLM è°ƒç”¨
try:
    from sessions_spawn import sessions_spawn
    from sessions_history import sessions_history
    SESSIONS_AVAILABLE = True
except ImportError:
    print("âš ï¸ sessions_spawn ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
    SESSIONS_AVAILABLE = False


def build_analyst_prompt(role: str, task: str, data: Dict[str, Any]) -> str:
    """æ„å»ºåˆ†æå¸ˆæç¤ºè¯"""
    
    role_prompts = {
        "åŸºæœ¬é¢åˆ†æå¸ˆ": """ä½ æ˜¯ä¸€ä½èµ„æ·±åŸºæœ¬é¢åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹æ•°æ®å¹¶è¾“å‡º JSONï¼š
{
    "rating": "BUY/HOLD/SELL",
    "confidence": 0.0-1.0,
    "targetPrice": ç›®æ ‡ä»·æ ¼,
    "reasoning": "åˆ†æç†ç”±",
    "keyStrengths": ["ä¼˜åŠ¿ 1", "ä¼˜åŠ¿ 2"],
    "keyRisks": ["é£é™© 1", "é£é™© 2"]
}

æ•°æ®ï¼š
{data}

åªè¾“å‡º JSONï¼Œä¸è¦ Markdownã€‚""",

        "æŠ€æœ¯åˆ†æå¸ˆ": """ä½ æ˜¯ä¸€ä½èµ„æ·±æŠ€æœ¯åˆ†æå¸ˆã€‚è¯·åˆ†ææŠ€æœ¯æŒ‡æ ‡å¹¶è¾“å‡º JSONï¼š
{
    "rating": "BUY/HOLD/SELL",
    "confidence": 0.0-1.0,
    "trendDirection": "UPTREND/DOWNTREND/SIDEWAYS",
    "reasoning": "åˆ†æç†ç”±",
    "supportLevel": æ”¯æ’‘ä½,
    "resistanceLevel": é˜»åŠ›ä½
}

æ•°æ®ï¼š
{data}

åªè¾“å‡º JSONï¼Œä¸è¦ Markdownã€‚""",

        "èˆ†æƒ…åˆ†æå¸ˆ": """ä½ æ˜¯ä¸€ä½èˆ†æƒ…åˆ†æå¸ˆã€‚è¯·åˆ†ææƒ…ç»ªæ•°æ®å¹¶è¾“å‡º JSONï¼š
{
    "rating": "BUY/HOLD/SELL",
    "confidence": 0.0-1.0,
    "sentimentScore": -1.0 åˆ° 1.0,
    "reasoning": "åˆ†æç†ç”±",
    "newsAssessment": "æ­£é¢/ä¸­æ€§/è´Ÿé¢",
    "socialAssessment": "æ­£é¢/ä¸­æ€§/è´Ÿé¢"
}

æ•°æ®ï¼š
{data}

åªè¾“å‡º JSONï¼Œä¸è¦ Markdownã€‚""",

        "é£é™©ç®¡ç†å¸ˆ": """ä½ æ˜¯ä¸€ä½é£é™©ç®¡ç†å¸ˆã€‚è¯·è¯„ä¼°é£é™©å¹¶è¾“å‡º JSONï¼š
{
    "riskLevel": "LOW/MEDIUM/HIGH",
    "positionLimit": 0.0-1.0,
    "stopLoss": æ­¢æŸä»·,
    "takeProfit": æ­¢ç›ˆä»·,
    "reasoning": "è¯„ä¼°ç†ç”±",
    "keyRisks": ["é£é™© 1", "é£é™© 2"]
}

æ•°æ®ï¼š
{data}

åªè¾“å‡º JSONï¼Œä¸è¦ Markdownã€‚"""
    }
    
    prompt = role_prompts.get(role, "åˆ†æä»¥ä¸‹æ•°æ®å¹¶è¾“å‡º JSONï¼š{data}")
    return prompt.format(data=json.dumps(data, indent=2, ensure_ascii=False))


def call_llm_via_sessions(prompt: str, timeout: int = 60) -> str:
    """
    é€šè¿‡ sessions_spawn è°ƒç”¨çœŸå® LLM
    """
    if not SESSIONS_AVAILABLE:
        raise RuntimeError("sessions_spawn ä¸å¯ç”¨")
    
    print(f"   ğŸ¤– åˆ›å»º LLM åˆ†æä¼šè¯...")
    
    # åˆ›å»ºå­ä»£ç†ä¼šè¯
    session_key = sessions_spawn(
        task=prompt,
        label="llm_analyst",
        runtime="subagent",
        mode="run",
        cleanup="delete",
        timeout_seconds=timeout
    )
    
    print(f"   ğŸ“¡ ç­‰å¾… LLM å“åº” (ä¼šè¯ï¼š{session_key})...")
    
    # è·å–ä¼šè¯å†å² (LLM å“åº”)
    history = sessions_history(session_key=session_key, limit=5)
    
    # æå– LLM å“åº”
    if history and 'messages' in history:
        for msg in reversed(history['messages']):
            if msg.get('role') == 'assistant':
                return msg.get('content', '')
    
    raise RuntimeError("æ— æ³•è·å– LLM å“åº”")


def parse_json_response(response: str) -> Dict[str, Any]:
    """è§£æ JSON å“åº”"""
    try:
        return json.loads(response.strip())
    except:
        import re
        match = re.search(r'\{.*\}', response, re.DOTALL)
        if match:
            return json.loads(match.group())
        raise ValueError(f"JSON è§£æå¤±è´¥ï¼š{response[:200]}")


def analyze_with_real_llm(role: str, data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä½¿ç”¨çœŸå® LLM è¿›è¡Œåˆ†æ
    
    å®Œæ•´æµç¨‹:
    1. æ„å»ºæç¤ºè¯
    2. è°ƒç”¨ sessions_spawn
    3. è§£æ JSON å“åº”
    4. è¿”å›ç»“æœ
    """
    print(f"\nğŸ“Š {role} æ­£åœ¨åˆ†æ...")
    
    # 1. æ„å»ºæç¤ºè¯
    prompt = build_analyst_prompt(role, "åˆ†æ", data)
    
    # 2. ä¿å­˜æç¤ºè¯
    os.makedirs('logs/llm_prompts', exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"logs/llm_prompts/{role}_{timestamp}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    # 3. è°ƒç”¨çœŸå® LLM
    try:
        llm_response = call_llm_via_sessions(prompt, timeout=60)
        
        # 4. è§£æå“åº”
        result = parse_json_response(llm_response)
        
        # 5. æ·»åŠ å…ƒæ•°æ®
        result['role'] = role
        result['timestamp'] = datetime.now().isoformat()
        result['llm_used'] = True
        
        print(f"   âœ… {role} å®Œæˆåˆ†æ")
        print(f"      è¯„çº§ï¼š{result.get('rating', 'N/A')}")
        print(f"      ç½®ä¿¡åº¦ï¼š{result.get('confidence', 0):.1%}")
        
        return result
        
    except Exception as e:
        print(f"   âŒ {role} åˆ†æå¤±è´¥ï¼š{e}")
        # è¿”å›ç©ºç»“æœä½†ä¸ä¸­æ–­æµç¨‹
        return {
            'role': role,
            'error': str(e),
            'llm_used': True,
            'timestamp': datetime.now().isoformat()
        }


# æµ‹è¯•
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¤– çœŸå® LLM åˆ†æå¸ˆ - æµ‹è¯•")
    print("="*60)
    
    test_data = {
        'symbol': 'GOOGL',
        'pe_ratio': 25.5,
        'roe': 0.28,
        'revenue_growth': 0.12
    }
    
    if SESSIONS_AVAILABLE:
        print(f"\nâœ… sessions_spawn å¯ç”¨ï¼Œå°†è°ƒç”¨çœŸå® LLM")
        result = analyze_with_real_llm("åŸºæœ¬é¢åˆ†æå¸ˆ", test_data)
        print(f"\nç»“æœï¼š{json.dumps(result, indent=2, ensure_ascii=False)}")
    else:
        print(f"\nâš ï¸ sessions_spawn ä¸å¯ç”¨ï¼Œæ— æ³•æµ‹è¯•çœŸå® LLM è°ƒç”¨")
        print(f"   æç¤ºè¯å·²ä¿å­˜åˆ° logs/llm_prompts/")
