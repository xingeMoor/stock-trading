"""
ç»Ÿä¸€æ•°æ®æ¥å£ v2 - æ”¯æŒ A è‚¡ + ç¾è‚¡å¤šæ•°æ®æº

åŠŸèƒ½:
1. ç»Ÿä¸€æ¥å£è®¿é—® A è‚¡ (akshare) å’Œç¾è‚¡ (Massive API) æ•°æ®
2. æ™ºèƒ½ç¼“å­˜æœºåˆ¶ (å†…å­˜ + SQLite)
3. è‡ªåŠ¨é™çº§å’Œæ•…éšœè½¬ç§»
4. æ ‡å‡†åŒ–çš„æ•°æ®æ ¼å¼

ä½œè€…ï¼šQ è„‘é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
æ—¥æœŸï¼š2026-03-01
"""
import os
import sys
import json
import sqlite3
import hashlib
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod
import threading

import pandas as pd

# ============================================================================
# ç¼“å­˜é…ç½®
# ============================================================================

CACHE_DIR = os.path.join(os.path.dirname(__file__), '..', 'data', 'cache')
os.makedirs(CACHE_DIR, exist_ok=True)

DB_PATH = os.path.join(CACHE_DIR, 'data_cache.db')


class CacheTTL:
    """ç¼“å­˜è¿‡æœŸæ—¶é—´é…ç½® (ç§’)"""
    KLINE_DAILY = 3600          # æ—¥çº¿æ•°æ®ï¼š1 å°æ—¶
    KLINE_MINUTE = 300          # åˆ†é’Ÿçº¿æ•°æ®ï¼š5 åˆ†é’Ÿ
    REALTIME = 30               # å®æ—¶è¡Œæƒ…ï¼š30 ç§’
    FUNDAMENTAL = 86400         # åŸºæœ¬é¢æ•°æ®ï¼š1 å¤©
    SNAPSHOT = 60               # å¿«ç…§æ•°æ®ï¼š1 åˆ†é’Ÿ
    DEFAULT = 1800              # é»˜è®¤ï¼š30 åˆ†é’Ÿ


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    total_entries: int = 0
    expired_entries: int = 0
    hit_count: int = 0
    miss_count: int = 0
    db_size_mb: float = 0.0
    
    @property
    def hit_rate(self) -> float:
        total = self.hit_count + self.miss_count
        return self.hit_count / total * 100 if total > 0 else 0.0


# ============================================================================
# ç¼“å­˜ç®¡ç†å™¨
# ============================================================================

class DataManagerCache:
    """
    æ•°æ®ç¼“å­˜ç®¡ç†å™¨
    
    æ”¯æŒ:
    - å†…å­˜ç¼“å­˜ (LRU)
    - SQLite æŒä¹…åŒ–ç¼“å­˜
    - TTL è‡ªåŠ¨è¿‡æœŸ
    - çº¿ç¨‹å®‰å…¨
    """
    
    def __init__(self, db_path: str = DB_PATH, max_memory_entries: int = 500):
        self._db_path = db_path
        self._max_memory_entries = max_memory_entries
        self._lock = threading.RLock()
        self._memory_cache: Dict[str, Dict[str, Any]] = {}
        self._stats = CacheStats()
        
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        conn = sqlite3.connect(self._db_path)
        try:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS data_cache (
                    key TEXT PRIMARY KEY,
                    data TEXT NOT NULL,
                    data_type TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    expires_at TIMESTAMP NOT NULL,
                    symbol TEXT,
                    market TEXT,
                    hit_count INTEGER DEFAULT 0
                )
            """)
            
            conn.execute("CREATE INDEX IF NOT EXISTS idx_symbol ON data_cache(symbol)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_market ON data_cache(market)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_expires ON data_cache(expires_at)")
            conn.commit()
        finally:
            conn.close()
    
    def _generate_key(self, data_type: str, symbol: str, market: str, 
                      params: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜ key"""
        params_str = json.dumps(params, sort_keys=True, default=str)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()[:16]
        return f"{market}:{data_type}:{symbol}:{params_hash}"
    
    def get(self, data_type: str, symbol: str, market: str, 
            params: Optional[Dict[str, Any]] = None) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        params = params or {}
        key = self._generate_key(data_type, symbol, market, params)
        
        with self._lock:
            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            if key in self._memory_cache:
                entry = self._memory_cache[key]
                if datetime.now() < entry['expires_at']:
                    self._stats.hit_count += 1
                    return entry['data']
                else:
                    del self._memory_cache[key]
            
            # æ£€æŸ¥æ•°æ®åº“ç¼“å­˜
            try:
                conn = sqlite3.connect(self._db_path)
                try:
                    cursor = conn.execute(
                        "SELECT data, expires_at FROM data_cache WHERE key = ?",
                        (key,)
                    )
                    row = cursor.fetchone()
                    
                    if row:
                        data_json, expires_at_str = row
                        expires_at = datetime.fromisoformat(expires_at_str)
                        
                        if datetime.now() < expires_at:
                            # æ›´æ–°å‘½ä¸­ç»Ÿè®¡
                            conn.execute(
                                "UPDATE data_cache SET hit_count = hit_count + 1 WHERE key = ?",
                                (key,)
                            )
                            conn.commit()
                            
                            data = json.loads(data_json)
                            
                            # æ›´æ–°å†…å­˜ç¼“å­˜
                            self._add_to_memory(key, data, expires_at, data_type, symbol, market)
                            
                            self._stats.hit_count += 1
                            return data
                        else:
                            # åˆ é™¤è¿‡æœŸæ•°æ®
                            conn.execute("DELETE FROM data_cache WHERE key = ?", (key,))
                            conn.commit()
                finally:
                    conn.close()
            except Exception:
                pass
            
            self._stats.miss_count += 1
            return None
    
    def set(self, data_type: str, symbol: str, market: str, 
            data: Any, ttl: int = CacheTTL.DEFAULT,
            params: Optional[Dict[str, Any]] = None) -> bool:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        params = params or {}
        key = self._generate_key(data_type, symbol, market, params)
        
        now = datetime.now()
        expires_at = now + timedelta(seconds=ttl)
        
        try:
            data_json = json.dumps(data, default=str)
            
            conn = sqlite3.connect(self._db_path)
            try:
                conn.execute(
                    """INSERT OR REPLACE INTO data_cache 
                       (key, data, data_type, created_at, expires_at, symbol, market)
                       VALUES (?, ?, ?, ?, ?, ?, ?)""",
                    (key, data_json, data_type, now.isoformat(), 
                     expires_at.isoformat(), symbol, market)
                )
                conn.commit()
            finally:
                conn.close()
            
            # æ›´æ–°å†…å­˜ç¼“å­˜
            self._add_to_memory(key, data, expires_at, data_type, symbol, market)
            
            return True
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜å†™å…¥å¤±è´¥ï¼š{e}")
            return False
    
    def _add_to_memory(self, key: str, data: Any, expires_at: datetime,
                       data_type: str, symbol: str, market: str):
        """æ·»åŠ åˆ°å†…å­˜ç¼“å­˜"""
        if len(self._memory_cache) >= self._max_memory_entries:
            # LRU: ç§»é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = min(self._memory_cache.keys(),
                           key=lambda k: self._memory_cache[k]['created_at'])
            del self._memory_cache[oldest_key]
        
        self._memory_cache[key] = {
            'data': data,
            'created_at': datetime.now(),
            'expires_at': expires_at,
            'data_type': data_type,
            'symbol': symbol,
            'market': market
        }
    
    def invalidate(self, symbol: Optional[str] = None, 
                   market: Optional[str] = None,
                   data_type: Optional[str] = None) -> int:
        """ä½¿ç¼“å­˜å¤±æ•ˆ"""
        with self._lock:
            # æ¸…ç†å†…å­˜ç¼“å­˜
            keys_to_remove = [
                k for k, v in self._memory_cache.items()
                if (symbol is None or v['symbol'] == symbol) and
                   (market is None or v['market'] == market) and
                   (data_type is None or v['data_type'] == data_type)
            ]
            for k in keys_to_remove:
                del self._memory_cache[k]
            
            # æ¸…ç†æ•°æ®åº“
            try:
                conn = sqlite3.connect(self._db_path)
                try:
                    conditions = []
                    params = []
                    
                    if symbol:
                        conditions.append("symbol = ?")
                        params.append(symbol)
                    if market:
                        conditions.append("market = ?")
                        params.append(market)
                    if data_type:
                        conditions.append("data_type = ?")
                        params.append(data_type)
                    
                    if conditions:
                        query = f"DELETE FROM data_cache WHERE {' AND '.join(conditions)}"
                        cursor = conn.execute(query, params)
                        conn.commit()
                        return cursor.rowcount
                finally:
                    conn.close()
            except Exception:
                pass
            
            return 0
    
    def clear_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        now = datetime.now().isoformat()
        
        with self._lock:
            # æ¸…ç†å†…å­˜
            expired_keys = [
                k for k, v in self._memory_cache.items()
                if datetime.now() > v['expires_at']
            ]
            for k in expired_keys:
                del self._memory_cache[k]
            
            # æ¸…ç†æ•°æ®åº“
            try:
                conn = sqlite3.connect(self._db_path)
                try:
                    cursor = conn.execute(
                        "DELETE FROM data_cache WHERE expires_at < ?",
                        (now,)
                    )
                    conn.commit()
                    return cursor.rowcount
                finally:
                    conn.close()
            except Exception:
                return 0
    
    def get_stats(self) -> CacheStats:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        try:
            conn = sqlite3.connect(self._db_path)
            try:
                cursor = conn.execute("SELECT COUNT(*) FROM data_cache")
                total = cursor.fetchone()[0]
                
                now = datetime.now().isoformat()
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM data_cache WHERE expires_at < ?",
                    (now,)
                )
                expired = cursor.fetchone()[0]
                
                db_size = os.path.getsize(self._db_path) if os.path.exists(self._db_path) else 0
                
                self._stats.total_entries = total
                self._stats.expired_entries = expired
                self._stats.db_size_mb = round(db_size / (1024 * 1024), 2)
                
                return self._stats
            finally:
                conn.close()
        except Exception:
            return self._stats


# ============================================================================
# æ•°æ®æä¾›è€…åŸºç±»
# ============================================================================

class DataProviderBase(ABC):
    """æ•°æ®æä¾›è€…åŸºç±»"""
    
    def __init__(self, cache: DataManagerCache):
        self.cache = cache
        self.market = "UNKNOWN"
    
    @abstractmethod
    def get_kline(self, symbol: str, start: str, end: str, 
                  **kwargs) -> pd.DataFrame:
        """è·å– K çº¿æ•°æ®"""
        pass
    
    @abstractmethod
    def get_realtime(self, symbol: str) -> Dict[str, Any]:
        """è·å–å®æ—¶è¡Œæƒ…"""
        pass
    
    @abstractmethod
    def get_fundamentals(self, symbol: str) -> Dict[str, Any]:
        """è·å–åŸºæœ¬é¢æ•°æ®"""
        pass
    
    def _save_to_cache(self, data_type: str, symbol: str, 
                       data: Any, ttl: int = CacheTTL.DEFAULT,
                       params: Optional[Dict[str, Any]] = None):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        self.cache.set(data_type, symbol, self.market, data, ttl, params)
    
    def _get_from_cache(self, data_type: str, symbol: str,
                        params: Optional[Dict[str, Any]] = None) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        return self.cache.get(data_type, symbol, self.market, params)


# ============================================================================
# A è‚¡æ•°æ®æä¾›è€…
# ============================================================================

class AShareProvider(DataProviderBase):
    """
    A è‚¡æ•°æ®æä¾›è€… - ä½¿ç”¨ akshare
    
    æ–‡æ¡£ï¼šhttps://akshare.xyz/
    å®‰è£…ï¼špip install akshare
    """
    
    def __init__(self, cache: DataManagerCache):
        super().__init__(cache)
        self.market = "A è‚¡"
        
        try:
            import akshare as ak
            self.ak = ak
        except ImportError:
            raise ImportError("è¯·å®‰è£… akshare: pip install akshare")
    
    def get_kline(self, symbol: str, start: str, end: str,
                  period: str = "daily", adjust: str = "qfq",
                  **kwargs) -> pd.DataFrame:
        """
        è·å– A è‚¡ K çº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001"
            start: å¼€å§‹æ—¥æœŸ YYYYMMDD æˆ– YYYY-MM-DD
            end: ç»“æŸæ—¥æœŸ YYYYMMDD æˆ– YYYY-MM-DD
            period: å‘¨æœŸ (daily/weekly/monthly)
            adjust: å¤æƒç±»å‹ (qfq/hfq/None)
        
        Returns:
            DataFrame with columns: date, open, high, low, close, volume, ...
        """
        # æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼
        start = start.replace('-', '')
        end = end.replace('-', '')
        
        # æ£€æŸ¥ç¼“å­˜
        cache_params = {'period': period, 'adjust': adjust}
        cached = self._get_from_cache('kline', symbol, cache_params)
        if cached is not None:
            df = pd.DataFrame(cached)
            df['date'] = pd.to_datetime(df['date'])
            return df
        
        # ä» akshare è·å–
        try:
            df = self.ak.stock_zh_a_hist(
                symbol=symbol,
                period=period,
                start_date=start,
                end_date=end,
                adjust=adjust
            )
            
            # æ ‡å‡†åŒ–åˆ—å
            df = df.rename(columns={
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'change_pct',
                'æ¶¨è·Œé¢': 'change',
                'æ¢æ‰‹ç‡': 'turnover'
            })
            
            # ç¡®ä¿æ—¥æœŸä¸º datetime ç±»å‹
            df['date'] = pd.to_datetime(df['date'])
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache('kline', symbol, df.to_dict('records'), 
                               CacheTTL.KLINE_DAILY, cache_params)
            
            return df
            
        except Exception as e:
            raise Exception(f"A è‚¡ K çº¿è·å–å¤±è´¥ï¼š{e}")
    
    def get_realtime(self, symbol: str) -> Dict[str, Any]:
        """è·å– A è‚¡å®æ—¶è¡Œæƒ…"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_from_cache('realtime', symbol)
        if cached is not None:
            return cached
        
        try:
            df = self.ak.stock_zh_a_spot_em()
            stock = df[df['ä»£ç '] == symbol]
            
            if stock.empty:
                return {'error': f'è‚¡ç¥¨ {symbol} æœªæ‰¾åˆ°', 'market': self.market}
            
            row = stock.iloc[0]
            data = {
                'symbol': symbol,
                'name': row.get('åç§°', ''),
                'price': float(row.get('æœ€æ–°ä»·', 0)),
                'open': float(row.get('ä»Šå¼€', 0)),
                'high': float(row.get('æœ€é«˜', 0)),
                'low': float(row.get('æœ€ä½', 0)),
                'prev_close': float(row.get('æ˜¨æ”¶', 0)),
                'volume': int(row.get('æˆäº¤é‡', 0)),
                'amount': float(row.get('æˆäº¤é¢', 0)),
                'change_pct': float(row.get('æ¶¨è·Œå¹…', 0)),
                'change': float(row.get('æ¶¨è·Œé¢', 0)),
                'turnover': float(row.get('æ¢æ‰‹ç‡', 0)),
                'market': self.market,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache('realtime', symbol, data, CacheTTL.REALTIME)
            
            return data
            
        except Exception as e:
            return {'error': str(e), 'market': self.market}
    
    def get_fundamentals(self, symbol: str) -> Dict[str, Any]:
        """è·å– A è‚¡åŸºæœ¬é¢æ•°æ®"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_from_cache('fundamental', symbol)
        if cached is not None:
            return cached
        
        try:
            info = self.ak.stock_individual_info_em(symbol=symbol)
            
            # è½¬æ¢ä¸ºå­—å…¸
            info_dict = {}
            for _, row in info.iterrows():
                if len(row) >= 2:
                    key = row.iloc[0]
                    value = row.iloc[1] if len(row) > 1 else None
                    info_dict[key] = value
            
            data = {
                'symbol': symbol,
                'market_cap': info_dict.get('æ€»å¸‚å€¼', 0),
                'float_market_cap': info_dict.get('æµé€šå¸‚å€¼', 0),
                'pe_ratio': info_dict.get('å¸‚ç›ˆç‡', 0),
                'pb_ratio': info_dict.get('å¸‚å‡€ç‡', 0),
                'roe': info_dict.get('ROE', 0),
                'eps': info_dict.get('æ¯è‚¡æ”¶ç›Š', 0),
                'industry': info_dict.get('è¡Œä¸š', ''),
                'area': info_dict.get('åœ°åŒº', ''),
                'market': self.market
            }
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache('fundamental', symbol, data, CacheTTL.FUNDAMENTAL)
            
            return data
            
        except Exception as e:
            return {'error': str(e), 'market': self.market}
    
    def get_stock_list(self) -> pd.DataFrame:
        """è·å– A è‚¡è‚¡ç¥¨åˆ—è¡¨"""
        return self.ak.stock_zh_a_spot_em()
    
    def get_etf_list(self) -> pd.DataFrame:
        """è·å– ETF åˆ—è¡¨"""
        return self.ak.fund_etf_spot_em()
    
    def get_sector_strength(self) -> pd.DataFrame:
        """è·å–æ¿å—å¼ºåº¦"""
        return self.ak.stock_sector_spot()


# ============================================================================
# ç¾è‚¡æ•°æ®æä¾›è€…
# ============================================================================

class USStockProvider(DataProviderBase):
    """
    ç¾è‚¡æ•°æ®æä¾›è€… - ä½¿ç”¨ Massive API
    
    æ–‡æ¡£ï¼šhttps://massive.com/
    """
    
    def __init__(self, cache: DataManagerCache, api_key: Optional[str] = None):
        super().__init__(cache)
        self.market = "US"
        
        # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å– API Key
        if api_key is None:
            import os
            from dotenv import load_dotenv
            load_dotenv()
            api_key = os.getenv('MASSIVE_API_KEY')
        
        if not api_key:
            raise ValueError("MASSIVE_API_KEY æœªè®¾ç½®")
        
        self.api_key = api_key
        self._client = None
    
    @property
    def client(self):
        """æ‡’åŠ è½½ Massive å®¢æˆ·ç«¯"""
        if self._client is None:
            try:
                from massive import RESTClient
                self._client = RESTClient(api_key=self.api_key)
            except ImportError:
                raise ImportError("è¯·å®‰è£… massive-api-client: pip install polygon-api-client")
        return self._client
    
    def get_kline(self, symbol: str, start: str, end: str,
                  multiplier: int = 1, timespan: str = "day",
                  **kwargs) -> pd.DataFrame:
        """
        è·å–ç¾è‚¡ K çº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "AAPL"
            start: å¼€å§‹æ—¥æœŸ YYYY-MM-DD æˆ– YYYYMMDD
            end: ç»“æŸæ—¥æœŸ YYYY-MM-DD æˆ– YYYYMMDD
            multiplier: æ—¶é—´é—´éš”å€æ•°
            timespan: æ—¶é—´å•ä½ (minute/hour/day/week/month)
        
        Returns:
            DataFrame with columns: date, open, high, low, close, volume, ...
        """
        # æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼
        if len(start) == 8:
            start = f"{start[:4]}-{start[4:6]}-{start[6:]}"
        if len(end) == 8:
            end = f"{end[:4]}-{end[4:6]}-{end[6:]}"
        
        # æ£€æŸ¥ç¼“å­˜
        cache_params = {'multiplier': multiplier, 'timespan': timespan}
        cached = self._get_from_cache('kline', symbol, cache_params)
        if cached is not None:
            df = pd.DataFrame(cached)
            df['date'] = pd.to_datetime(df['date'])
            return df
        
        # ä» Massive API è·å–
        try:
            aggs = self.client.get_aggs(
                ticker=symbol,
                multiplier=multiplier,
                timespan=timespan,
                from_=start,
                to=end,
                limit=5000
            )
            
            agg_list = list(aggs)
            if not agg_list:
                return pd.DataFrame()
            
            # è½¬æ¢ä¸º DataFrame
            data = []
            for item in agg_list:
                data.append({
                    'date': datetime.fromtimestamp(item.timestamp / 1000),
                    'open': float(item.open),
                    'high': float(item.high),
                    'low': float(item.low),
                    'close': float(item.close),
                    'volume': int(item.volume) if hasattr(item, 'volume') else 0,
                    'vwap': float(item.vwap) if hasattr(item, 'vwap') else None,
                    'transactions': int(item.transactions) if hasattr(item, 'transactions') else 0
                })
            
            df = pd.DataFrame(data)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            ttl = CacheTTL.KLINE_MINUTE if timespan == 'minute' else CacheTTL.KLINE_DAILY
            self._save_to_cache('kline', symbol, df.to_dict('records'), ttl, cache_params)
            
            return df
            
        except Exception as e:
            raise Exception(f"ç¾è‚¡ K çº¿è·å–å¤±è´¥ï¼š{e}")
    
    def get_realtime(self, symbol: str) -> Dict[str, Any]:
        """è·å–ç¾è‚¡å®æ—¶è¡Œæƒ…"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_from_cache('realtime', symbol)
        if cached is not None:
            return cached
        
        try:
            # è·å–å¿«ç…§æ•°æ®
            snapshot = self.client.get_snapshot_ticker("stocks", symbol)
            
            data = {
                'symbol': symbol,
                'name': snapshot.ticker if hasattr(snapshot, 'ticker') else symbol,
                'price': float(snapshot.last_trade.price) if hasattr(snapshot, 'last_trade') else 0,
                'open': float(snapshot.day.open) if hasattr(snapshot, 'day') else 0,
                'high': float(snapshot.day.high) if hasattr(snapshot, 'day') else 0,
                'low': float(snapshot.day.low) if hasattr(snapshot, 'day') else 0,
                'prev_close': float(snapshot.prev_day.close) if hasattr(snapshot, 'prev_day') else 0,
                'volume': int(snapshot.day.volume) if hasattr(snapshot, 'day') else 0,
                'change': float(snapshot.day.change) if hasattr(snapshot, 'day') else 0,
                'change_pct': float(snapshot.day.change_percent) if hasattr(snapshot, 'day') else 0,
                'market_cap': float(snapshot.market_cap) if hasattr(snapshot, 'market_cap') else None,
                'pe_ratio': float(snapshot.valuations.get('pe', 0)) if hasattr(snapshot, 'valuations') else None,
                'market': self.market,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache('realtime', symbol, data, CacheTTL.REALTIME)
            
            return data
            
        except Exception as e:
            return {'error': str(e), 'market': self.market}
    
    def get_fundamentals(self, symbol: str) -> Dict[str, Any]:
        """è·å–ç¾è‚¡åŸºæœ¬é¢æ•°æ®"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_from_cache('fundamental', symbol)
        if cached is not None:
            return cached
        
        try:
            # è·å–è‚¡ç¥¨è¯¦æƒ…
            details = self.client.get_ticker_details(symbol)
            
            data = {
                'symbol': symbol,
                'name': details.name if hasattr(details, 'name') else symbol,
                'market_cap': float(details.market_cap) if hasattr(details, 'market_cap') else None,
                'shares_outstanding': float(details.shares_outstanding) if hasattr(details, 'shares_outstanding') else None,
                'public_float': float(details.public_float) if hasattr(details, 'public_float') else None,
                'industry': details.sic_description if hasattr(details, 'sic_description') else None,
                'sector': None,  # Massive API ä¸ç›´æ¥æä¾›
                'employees': details.total_employees if hasattr(details, 'total_employees') else None,
                'headquarters': details.address.city if hasattr(details, 'address') and hasattr(details.address, 'city') else None,
                'founded': details.list_date if hasattr(details, 'list_date') else None,
                'description': details.description if hasattr(details, 'description') else None,
                'homepage': details.homepage_url if hasattr(details, 'homepage_url') else None,
                'market': self.market
            }
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache('fundamental', symbol, data, CacheTTL.FUNDAMENTAL)
            
            return data
            
        except Exception as e:
            return {'error': str(e), 'market': self.market}
    
    def get_snapshot_all(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ç¾è‚¡å¿«ç…§"""
        try:
            snapshots = self.client.get_snapshot_all("stocks")
            
            return [
                {
                    'symbol': s.ticker,
                    'price': float(s.last_trade.price),
                    'change_pct': float(s.change_percent),
                    'volume': int(s.day.volume)
                }
                for s in snapshots
            ]
        except Exception as e:
            return [{'error': str(e)}]
    
    def get_market_status(self) -> Dict[str, Any]:
        """è·å–å¸‚åœºçŠ¶æ€"""
        try:
            status = self.client.get_market_status()
            
            return {
                'market': status.market if hasattr(status, 'market') else 'unknown',
                'server_time': status.server_time if hasattr(status, 'server_time') else None,
                'after_hours': status.after_hours if hasattr(status, 'after_hours') else False,
                'early_hours': status.early_hours if hasattr(status, 'early_hours') else False
            }
        except Exception as e:
            return {'error': str(e)}


# ============================================================================
# ç»Ÿä¸€æ•°æ®æ¥å£
# ============================================================================

class DataProvider:
    """
    ç»Ÿä¸€æ•°æ®æ¥å£
    
    æä¾›å•ä¸€å…¥å£è®¿é—® A è‚¡å’Œç¾è‚¡æ•°æ®ï¼Œè‡ªåŠ¨é€‰æ‹©å¯¹åº”çš„æ•°æ®æä¾›è€…
    """
    
    _instances: Dict[str, DataProviderBase] = {}
    _cache: Optional[DataManagerCache] = None
    
    @classmethod
    def _get_cache(cls) -> DataManagerCache:
        """è·å–æˆ–åˆ›å»ºç¼“å­˜ç®¡ç†å™¨"""
        if cls._cache is None:
            cls._cache = DataManagerCache()
        return cls._cache
    
    @classmethod
    def _get_provider(cls, market: str) -> DataProviderBase:
        """è·å–å¸‚åœºå¯¹åº”çš„æ•°æ®æä¾›è€…"""
        market = market.upper()
        market_map = {'A è‚¡': 'A è‚¡', 'ASHARE': 'A è‚¡', 'CN': 'A è‚¡', 
                      'US': 'US', 'USA': 'US', 'ç¾è‚¡': 'US'}
        
        normalized_market = market_map.get(market.upper(), market)
        
        if normalized_market not in cls._instances:
            cache = cls._get_cache()
            
            if normalized_market == 'A è‚¡':
                cls._instances[normalized_market] = AShareProvider(cache)
            elif normalized_market == 'US':
                cls._instances[normalized_market] = USStockProvider(cache)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœºï¼š{market}")
        
        return cls._instances[normalized_market]
    
    @classmethod
    def get_kline(cls, symbol: str, market: str, start: str, end: str,
                  **kwargs) -> pd.DataFrame:
        """
        ç»Ÿä¸€è·å– K çº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market: å¸‚åœº (A è‚¡/US)
            start: å¼€å§‹æ—¥æœŸ
            end: ç»“æŸæ—¥æœŸ
            **kwargs: é¢å¤–å‚æ•°ä¼ é€’ç»™å…·ä½“æä¾›è€…
        
        Returns:
            DataFrame with OHLCV data
        """
        provider = cls._get_provider(market)
        return provider.get_kline(symbol, start, end, **kwargs)
    
    @classmethod
    def get_realtime(cls, symbol: str, market: str) -> Dict[str, Any]:
        """ç»Ÿä¸€è·å–å®æ—¶è¡Œæƒ…"""
        provider = cls._get_provider(market)
        return provider.get_realtime(symbol)
    
    @classmethod
    def get_fundamentals(cls, symbol: str, market: str) -> Dict[str, Any]:
        """ç»Ÿä¸€è·å–åŸºæœ¬é¢æ•°æ®"""
        provider = cls._get_provider(market)
        return provider.get_fundamentals(symbol)
    
    @classmethod
    def get_cache_stats(cls) -> CacheStats:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        cache = cls._get_cache()
        return cache.get_stats()
    
    @classmethod
    def clear_cache(cls, symbol: Optional[str] = None,
                    market: Optional[str] = None,
                    data_type: Optional[str] = None) -> int:
        """æ¸…é™¤ç¼“å­˜"""
        cache = cls._get_cache()
        return cache.invalidate(symbol, market, data_type)


# ============================================================================
# æµ‹è¯•å‡½æ•°
# ============================================================================

def test_data_provider():
    """æµ‹è¯•ç»Ÿä¸€æ•°æ®æ¥å£"""
    print("=" * 70)
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€æ•°æ®æ¥å£ v2")
    print("=" * 70)
    
    # æµ‹è¯• A è‚¡
    print("\n1ï¸âƒ£  A è‚¡æ•°æ®æµ‹è¯•...")
    try:
        provider = DataProvider._get_provider('A è‚¡')
        
        # æµ‹è¯• K çº¿
        print("   ğŸ“Š è·å–å¹³å®‰é“¶è¡Œ (000001) K çº¿...")
        df = provider.get_kline('000001', '20250101', '20260228')
        print(f"   âœ… è·å– {len(df)} æ¡æ•°æ®")
        print(f"   ğŸ“ˆ æœ€æ–°æ”¶ç›˜ä»·ï¼šÂ¥{df['close'].iloc[-1]:.2f}")
        
        # æµ‹è¯•å®æ—¶è¡Œæƒ…
        print("\n   ğŸ’¹ è·å–å®æ—¶è¡Œæƒ…...")
        realtime = provider.get_realtime('000001')
        if 'error' not in realtime:
            print(f"   âœ… {realtime['name']}: Â¥{realtime['price']} ({realtime['change_pct']}%)")
        else:
            print(f"   âš ï¸  {realtime.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æµ‹è¯•åŸºæœ¬é¢
        print("\n   ğŸ“‹ è·å–åŸºæœ¬é¢æ•°æ®...")
        fundamentals = provider.get_fundamentals('000001')
        if 'error' not in fundamentals:
            print(f"   âœ… å¸‚å€¼ï¼š{fundamentals.get('market_cap', 'N/A')}")
            print(f"   âœ… PE: {fundamentals.get('pe_ratio', 'N/A')}")
        else:
            print(f"   âš ï¸  {fundamentals.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"   âŒ A è‚¡æµ‹è¯•å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•ç¾è‚¡
    print("\n2ï¸âƒ£  ç¾è‚¡æ•°æ®æµ‹è¯•...")
    try:
        provider = DataProvider._get_provider('US')
        
        # æµ‹è¯• K çº¿
        print("   ğŸ“Š è·å– AAPL K çº¿...")
        df = provider.get_kline('AAPL', '2025-01-01', '2026-02-28')
        print(f"   âœ… è·å– {len(df)} æ¡æ•°æ®")
        print(f"   ğŸ“ˆ æœ€æ–°æ”¶ç›˜ä»·ï¼š${df['close'].iloc[-1]:.2f}")
        
        # æµ‹è¯•å®æ—¶è¡Œæƒ…
        print("\n   ğŸ’¹ è·å–å®æ—¶è¡Œæƒ…...")
        realtime = provider.get_realtime('AAPL')
        if 'error' not in realtime:
            print(f"   âœ… {realtime.get('name', 'AAPL')}: ${realtime.get('price', 0):.2f} ({realtime.get('change_pct', 0)}%)")
        else:
            print(f"   âš ï¸  {realtime.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æµ‹è¯•åŸºæœ¬é¢
        print("\n   ğŸ“‹ è·å–åŸºæœ¬é¢æ•°æ®...")
        fundamentals = provider.get_fundamentals('AAPL')
        if 'error' not in fundamentals:
            print(f"   âœ… å¸‚å€¼ï¼š{fundamentals.get('market_cap', 'N/A')}")
            print(f"   âœ… å‘˜å·¥æ•°ï¼š{fundamentals.get('employees', 'N/A')}")
        else:
            print(f"   âš ï¸  {fundamentals.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"   âŒ ç¾è‚¡æµ‹è¯•å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•ç¼“å­˜
    print("\n3ï¸âƒ£  ç¼“å­˜ç»Ÿè®¡...")
    stats = DataProvider.get_cache_stats()
    print(f"   ğŸ“Š ç¼“å­˜æ¡ç›®ï¼š{stats.total_entries}")
    print(f"   ğŸ“Š å‘½ä¸­ç‡ï¼š{stats.hit_rate:.1f}%")
    print(f"   ğŸ’¾ æ•°æ®åº“å¤§å°ï¼š{stats.db_size_mb} MB")
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    test_data_provider()
